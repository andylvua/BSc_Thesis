\chapter{Methodology}

\section{\textit{RangeCIR} dataset}\label{data_collection}

\begin{figure}[tbh]
    \centering
    \subfloat[Experimental environment with anchor setup.]{%
        \includegraphics[height=6.5cm]{Figures/methodology/dataset_env.png}
        \label{fig:environment}
    }
    \subfloat[UWB tag device.]{%
        \includegraphics[height=6.5cm]{Figures/methodology/tag.png}
        \label{fig:tag}
    }
    \caption{Setup used for \textit{RangeCIR} dataset collection.}
    \label{fig:dataset_setup}
\end{figure}

To the best of the author's knowledge, no publicly available datasets are compatible with the hardware used in this study. Therefore, a custom dataset was acquired through a controlled experimental campaign.

\begin{figure}[tbh]
\hspace*{-20pt} % To align the legend of the figure with caption, looks more appealing
\includegraphics[width=0.75\textwidth]{Figures/methodology/dataset_scheme.pdf}
\centering
\caption{Schematic of the dataset collection setup.}
\label{fig:exp_topology}
\end{figure}

Measurements were carried out using the SynchronicIT SFM10-DEV development board\footnote{\url{https://synchronicit.nl/hardware?topic=SFM10-DEV}}, based on the SFM10-MOD, an IEEE 802.15.4z-compliant IR-UWB module built around the NXP Trimension OL23D0 chipset. The radio was configured to operate on UWB channel 5 (central frequency of~\SI{6489.6}{\mega\hertz}, bandwidth of \SI{499.2}{\mega\hertz}). The SHR preamble length was set to 32 symbols. Ranging and CIR acquisition were powered by custom firmware discussed in \autoref{ranging_system}. 

The data collection took place in an approximately $6 \times 8$~\si{\meter} university classroom. Four fixed anchors were placed at the room's corners, while a single tag was moved along a predefined grid confined to one quadrant of the room. This configuration was chosen to reduce the data collection efforts and time by minimizing the spatial symmetry duplications without loss of generality. At each grid point, the tag was rotated around its vertical axis through a~\SI{360}{\degree} sweep to capture variability in directional antenna characteristics, while its location was kept constant. All devices were mounted vertically at a height of~\SI{120}{\centi\metre}, taking antenna polarization into account. \autoref{fig:dataset_setup} shows the data collection environment and setup, while~\autoref{fig:exp_topology} illustrates the layout, including anchor placements and the tagâ€™s movement grid.

Distance measurements were acquired using the ADS-TWR method, with approximately 50,000 samples collected per tag position at a sampling frequency of~\SI{270}{\hertz}. Each measurement recorded both the estimated distance and the corresponding CIR associated with the Final packet of the TWR protocol (see \autoref{theory:twr} for further details on TWR). A total of 136 CIR samples were captured per measurement, comprising 8 samples preceding and 127 samples following the first path. This sampling strategy was determined empirically to balance data compactness with the need to capture sufficient environmental detail for subsequent error correction.

To model realistic NLoS conditions, dynamic human obstructions were introduced by instructing five volunteers to move pseudo-randomly throughout the room, intermittently blocking the direct paths between the transceivers. Given the inherent unpredictability of such movements, manual labeling of each measurement as LoS or NLoS was infeasible. However, reliable annotation is essential for maintaining dataset balance, enabling context-aware analysis, and supporting future studies focused on classification tasks. An automated optical tracking system was therefore employed to determine LoS/NLoS conditions during data collection. A comprehensive description of the tracking system implementation is presented in \autoref{tracking_system}.

To ensure data quality and balance, we developed a custom real-time graphical user interface (GUI). During the data collection process, the GUI was projected on the wall to be clearly visible to all participants and displayed: live distance measurements, system status for each anchor, the current ratio of NLoS to LoS measurements, and the cumulative count of recorded samples. Volunteers were guided to maintain an NLoS measurement ratio exceeding \SI{50}{\percent}, thereby ensuring a dataset with sufficient variability for effective model training.

The known locations of the tag and anchors were subsequently translated into the ground truth distances, and individual measurement sessions were aggregated accordingly. To this end, the resulting dataset includes estimated and ground truth distances, LoS/NLoS labels, and synchronized CIR measurements. This dataset, referred to as \textit{RangeCIR}, has been made publicly available to support reproducibility and to promote further research on NLoS error mitigation and channel classification~\cite{yaroshevych_2025_rangecir}.

\section{Proposed IPS pipeline}

\begin{figure}[tbh]
\includegraphics[width=\textwidth]{Figures/methodology/pipeline.pdf}
\centering
\caption{The proposed IPS pipeline.}
\label{fig:pipeline}
\end{figure}

The pipeline of the proposed IPS is depicted in \autoref{fig:pipeline}. The following part of this section will separately discuss each of its three major modules: 

\begin{enumerate}
    \item Ranging system;
    \item Error mitigation model;
    \item Kalman filter.
\end{enumerate}

\subsection{Ranging system}\label{ranging_system}

\paragraph{Architecture.}

\begin{figure}[tbh]
\includegraphics[width=0.85\textwidth]{Figures/methodology/superframe_structure.pdf}
\centering
\caption{Superframe structure.}
\label{fig:superframe}
\end{figure}

\begin{figure}[tbh]
\includegraphics[width=0.75\textwidth]{Figures/methodology/slot_correction.pdf}
\centering
\caption{Slot correction mechanism.}
\label{fig:slot_correction}
\end{figure}

The ranging system forms the foundational layer of the proposed IPS pipeline, enabling continuous acquisition of inter-device distances used for localization. The system architecture differentiates between two roles: \textit{anchors}, which are statically deployed at known locations $\mathbf{p}_{A_i} = (x_{A_i}, y_{A_i}) \in \mathbb{R}^2$, and a \textit{tag}, which is mobile and continuously performs distance measurements relative to each anchor with unknown position $\mathbf{p}_T = (x_T, y_T) \in \mathbb{R}^2$ to be estimated. 

All devices operate under a custom TDMA protocol\footnote{The design of the TDMA protocol and the slot correction mechanism used in this study was inspired by Qorvo's UWB software stack, which implements similar synchronization strategies: \url{https://www.qorvo.com/products/d/da007992}.} (refer to \autoref{tdma} for background). Each ranging operation is executed within a so-called TDMA \emph{superframe} structure of duration $T_{SF}$, subdivided into $N$ non-overlapping slots, each uniquely assigned to an anchor. This structure is shown in \autoref{fig:superframe}. At the start of every superframe, all devices are awakened via a timer interrupt. Notably, each device maintains its own local superframe timing, derived from its internal clock. During its assigned slot, the anchor initiates the transaction by broadcasting a \emph{Poll} message. Upon reception, the tag responds with a \emph{Response} message, embedding timing feedback, which will be detailed later. The anchor finalizes the transaction with a delayed transmission of the \emph{Final} message, which includes all timing information necessary for the tag to compute the ToF. This transaction follows the ADS-TWR protocol, discussed in \autoref{adstwr}, and enables the tag $T$ to estimate the raw range $\hat{d}_{A_i,T}$ between itself and each anchor $A_i$:
\begin{equation}
\hat{d}_{A_i,T} = d_{A_i,T} + e_{A_i,T},\label{eq:raw_range}
\end{equation}
where $e_{A_i,T}$ denotes the aggregated ranging error component, which is consequently mitigated using the CIR-driven error mitigation model, and $d_{A_i,T}$ is the true geometric distance between the tag and the $i$-th anchor, defined as the Euclidean norm:
\begin{equation} 
d_{A_i,T} = \left\| \mathbf{p}_T - \mathbf{p}_{A_i} \right\|.\label{eq:true_distance} 
\end{equation}

To maintain TDMA slot integrity, precise temporal alignment between anchors is essential. To this end, the tag computes a \textit{slot correction} value $\Delta t_{\text{slot}}$ upon reception of each Poll message, quantifying the offset between its expected and actual arrival times relative to the start of the superframe. This correction term is then embedded in the Response message and fed back to the anchor, which uses it to dynamically adjust the scheduling of subsequent superframes, thereby preserving tight synchronization. \autoref{fig:slot_correction} illustrates this mechanism in detail.

The source code implementing the ranging system firmware is publicly available on GitHub\footnote{\url{https://github.com/andylvua/SFM10-DEV-TWR}}, supporting reproducibility and further development.

\paragraph{CIR acquisition.}

A core feature of the proposed system is the ability to extract and transmit the channel impulse response $\text{CIR}_{A_i,T}$ associated with each ranging transaction, which enables subsequent error correction with the proposed model, as illustrated in~\autoref{fig:pipeline}. Depending on the device configuration, CIR data may be acquired either by the tag upon reception of the Final message, or by the anchor upon reception of the Response message. Each CIR accumulator contains up to 255 samples, with each sample comprising a 2-byte real and a 2-byte imaginary component, resulting in a raw data footprint of 4 bytes per sample.

However, our analysis reveals that approximately \SI{93}{\percent} of the differences between sequential raw CIR values (real and imaginary parts are treated as separate sequences and differenced individually) can be efficiently represented using only 1 byte. Therefore, to increase the data transmission rate and subsequently improve the ranging frequency, the system implements a 7-bit adaptive delta-encoding scheme for CIR compression. The encoding proceeds as follows:

\begin{enumerate} 
    \item for each CIR sample component (real or imaginary), the difference $\Delta x = x_i - x_{i-1}$ is computed;
    \item if $|\Delta x| \leq 63$, the delta is encoded in a single byte, using low 7 bits for value, and the most significant bit as a continuation flag (set to 0);
    \item if $|\Delta x| > 63$, a two-byte representation is used. The first byte contains the high 7 bits of the delta, with the continuation flag set to 1. The second byte stores the remaining 8 bits. 
\end{enumerate} 
As a result, the effective measurement frequency is increased by over \SI{20}{\percent} compared to transmitting raw samples, as observed for CIR sequences containing 136 samples. Both the encoding on the device side and the decoding on the host side impose negligible computational overhead.

\subsection{Error mitigation model}

As discussed in \autoref{error_sources}, raw distance measurements are inherently affected by various sources of error, including multipath propagation and NLoS conditions. These conditions introduce error $e_{A_i,T}$ between the true distance $d_{A_i,T}$ and the measured distance $\hat{d}_{A_i,T}$ (\autoref{eq:raw_range}). To improve localization accuracy, it is imperative to estimate and correct for this error component prior to position estimation. 

To this end, we employ a learning-based error mitigation module $\mathcal{M}$ that is used to infer the error estimate $\hat{e}_{A_i,T}$ as a function of the channel impulse response (see \autoref{cir_theory} for a detailed discussion of CIR fundamentals), denoted $\text{CIR}_{A_iT}$:
\begin{equation}
    \hat{e}_{A_i,T} = \mathcal{M}(\text{CIR}_{A_iT}),
\end{equation}
which is then subtracted from the raw measurement to obtain a corrected range:
\begin{equation}
    d'_{A_i,T} = \hat{d}_{A_i,T} - \hat{e}_{A_i,T}.
\end{equation}

The corrected range $d'_{A_i,T}$ later serves as the input to the proposed Kalman filter, enabling more accurate and robust state estimation. As mentioned before, \autoref{fig:pipeline} illustrates this proposed pipeline.

\paragraph{Foundational model.}

The proposed model $\mathcal{M}$ builds upon the \emph{REMNet (Range Error Mitigation Network)}, deep residual architecture introduced by Simone Angarano et al. in~\cite{Simone2021UWB}, which demonstrated the feasibility of learning ranging errors from CIR. In the original formulation of REMNet architecture, the input CIR vector of length $K$, is first transformed through a 1D convolutional layer that extracts $F$ low-level features. Unless otherwise specified, all convolutional and fully connected layers are followed by ReLU activations. This initial representation is passed through a stack of $N$ identical residual reduction modules (RRMs), each performing two main operations: residual feature transformation and temporal dimensionality reduction. 

\begin{figure}[thb]
\includegraphics[width=\textwidth]{Figures/methodology/remnet_compat.pdf}
\centering
\caption[Proposed A-REMNet architecture.]{Proposed A-REMNet architecture. Figure is adapted from Simone Angarano et al.~\cite{Simone2021UWB}, with permission from the authors.}
\label{fig:architecture}
\end{figure}

Each RRM can be functionally described as:
\begin{equation}
    \text{RRM}(\mathbf{X}) = \text{Red}(\text{Res}(\mathbf{X})),
\end{equation}
where $\mathbf{X} \in \mathbb{R}^{K \times F}$ is the input tensor, $\text{Res}(\cdot)$ denotes a residual transformation unit, and $\text{Red}(\cdot)$ is a dimensionality reduction block. The residual unit is defined as:
\begin{equation}
    \text{Res}(\mathbf{X}) = \text{SE}(\text{Conv1D}(\mathbf{X})) + \mathbf{X},
\end{equation}
where $\text{Conv1D}$ denotes a 1D convolution, and $\text{SE}(\cdot)$ is a squeeze-and-excitation block. The SE block introduces channel-wise attention by using global average pooling to extract channel descriptors, followed by a two-layer bottleneck that produces scaling factors for self-gating, i.e., reweighting each channel by a value derived from itself. Given an intermediate feature map $ \mathbf{X} \in \mathbb{R}^{K \times F} $, the SE operation is defined as:
\begin{equation}
    \text{SE}(\mathbf{X}) = \mathbf{X} \cdot \boldsymbol{\alpha}, \qquad \boldsymbol{\alpha} = \text{FC}_2\left(\text{FC}_1(\text{GAP}(\mathbf{X}))\right),
\end{equation}
where $\text{GAP}(x) = \frac{1}{K} \sum_{k=1}^{K} x_{k,:}$ performs global average pooling over the temporal axis, and $\text{FC}_1: \mathbb{R}^{1 \times F} \rightarrow \mathbb{R}^{1 \times F/r}$, $\text{FC}_2: \mathbb{R}^{1 \times F/r} \rightarrow \mathbb{R}^{1 \times F}$ are fully connected layers with ReLU and sigmoid activations, respectively. Here, $r$ is the reduction ratio controlling the compression rate in the bottleneck. The resulting scaling vector $\boldsymbol{\alpha} \in \mathbb{R}^{1 \times F}$ modulates the importance of each feature channel.

Following the residual transformation, the RRM performs temporal downsampling through the reduction block, which comprises two parallel strided convolutional branches:
\begin{equation}
    \text{Red}(\mathbf{X}) = \text{Conv1D}_1(\mathbf{X}) + \text{Conv1D}_2(\mathbf{X}),
\end{equation}
where $\text{Conv1D}_1$ and $\text{Conv1D}_2$ utilize different kernel sizes to capture both coarse- and fine-grained features. Each branch produces a feature map in $\mathbb{R}^{K/2 \times F}$, preserving the feature dimensionality while reducing the temporal resolution.

After passing through $N$ successive RRMs, the resulting feature tensor lies in $\mathbb{R}^{K / 2^N \times F}$. This tensor is then flattened and passed through a dropout layer to mitigate overfitting, followed by a fully connected layer with linear activation that outputs the final regressive error estimate $\hat{e}_{A_i,T}$.

\paragraph{Proposed \emph{A-REMNet} approach.}
We introduce two key enhancements designed to improve the model's representational capacity and performance. First, in contrast to the original architecture, which discards CIR phase information by utilizing only its magnitude, we retain the full complex-valued CIR in a two-channel format (separating real and imaginary components), i.e.,
\begin{equation}
    \text{CIR}_{A_iT} \in \mathbb{R}^{K \times 2}.
\end{equation}
We believe this allows the network to learn richer signal characteristics that would otherwise be discarded if only the magnitude was employed.

Second, and more critically, we augment the architecture with a temporal self-attention unit, yielding the proposed \emph{Attention-enhanced Range Error Mitigation Network (A-REMNet)}, illustrated in \autoref{fig:architecture}. The proposed unit $\text{Att}(\cdot)$ is embedded directly in RRM before the residual unit, modifying the RRM as:
\begin{equation}
    \text{RRM}(\mathbf{X}) = \text{Red}(\text{Res}(\text{Att}(\mathbf{X}))).
\end{equation}
Unlike the SE block, the self-attention module operates along the temporal dimension of the CIR, allowing the model to capture long-range dependencies that conventional convolutional kernels may overlook. Inspired by the Transformer architecture introduced in~\cite{attention}, we adopt a multi-head self-attention (MHSA) mechanism to enable the model to attend to multiple subspaces of the temporal sequence in parallel, followed by a layer normalization on the residual branch to stabilize the learning process:
\begin{equation}
    \text{Att}(\mathbf{X}) = \text{LayerNorm}(\text{MHSA}(\mathbf{X}) + \mathbf{X}).
\end{equation}

Formally, given an input tensor $\mathbf{X} \in \mathbb{R}^{K \times F}$ at a hidden layer, where $F$ denotes the feature embedding dimension, the multi-head self-attention mechanism computes attention outputs as:
\begin{equation}
    \text{MHSA}(\mathbf{X}) = \text{Concat}(\text{head}_1, \dots, \text{head}_h) W^O,
\end{equation}
where each attention head is given by:
\begin{equation}
    \text{head}_i = \text{Attention}(\mathbf{X} W_i^Q, \mathbf{X} W_i^K, \mathbf{X} W_i^V),
\end{equation}
and the scaled dot-product attention mechanism is defined as:
\begin{equation}
    \text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{softmax}\left( \frac{\mathbf{Q} \mathbf{K}^\top}{\sqrt{d_k}} \right) \mathbf{V},
\end{equation}
where $h$ is the number of heads, and $W_i^Q \in \mathbb{R}^{F \times d_k}$, $W_i^K \in \mathbb{R}^{F \times d_k}$, $W_i^V \in \mathbb{R}^{F \times d_v}$, $W^O \in \mathbb{R}^{hd_v \times F}$ are learned projection matrices. Here, $d_k = d_v = F/h$ is the dimension of each attention head. This mechanism enables dynamic weighting of temporal features, targeted at making the model particularly effective in identifying non-local patterns and multipath structures indicative of NLoS conditions.

To provide the attention mechanism with information about the temporal ordering of CIR taps, we incorporate learnable positional encoding, following an approach similar to that used in many Transformer models~\cite{2019-bert, 2022-simple-yet}. A distinct embedding vector is assigned to each temporal index, and these vectors are added to the input features prior to the attention operation. For an intermediate feature map $\mathbf{X} \in \mathbb{R}^{K \times F}$, the position-augmented representation is computed as:
\begin{equation}
    \mathbf{X}' = \text{Dropout}(\mathbf{X} + \mathbf{P}),
\end{equation}
where $\mathbf{P} \in \mathbb{R}^{K \times F}$ is a learnable positional embedding matrix, and dropout is applied to prevent overfitting. This encoding enables the model to associate temporal positions with specific signal characteristics, which is particularly relevant given the structured nature of CIRs, where early and late taps often represent different propagation behaviors.

\subsection{Kalman filter}

As previously outlined, following the mitigation of ranging errors, the final stage of the proposed pipeline (\autoref{fig:pipeline}) performs sequential fusion and smoothing of the corrected measurements to estimate the tag's trajectory over time by applying an Extended Kalman Filter. This section details the implementation of the proposed EKF, building upon the theoretical background presented in \autoref{kalman_theory}.

The objective is to estimate the two-dimensional position and velocity of the mobile tag, denoted as the state vector:
\begin{equation}
        \mathbf{x}_k = [x_k, y_k, v_{x_k}, v_{y_k}]^\top \in \mathbb{R}^4,
\end{equation}
where $(x_k, y_k)$ and $(v_{x_k}, v_{y_k})$ represent the position and velocity components at time step $k$, respectively.

\paragraph{State transition model.}

Assuming constant velocity motion with small Gaussian perturbations, the dynamics of the tag are modeled by a linear time-invariant system:
\begin{equation}
    \mathbf{x}_k = \mathbf{F}_k \mathbf{x}_{k-1} + \mathbf{w}_{k-1},
\end{equation}
where the state transition matrix $\mathbf{F}_k$ incorporates the time increment $\Delta t$:
\begin{equation}
    \mathbf{F}_k =
    \begin{bmatrix}
        1 & 0 & \Delta t & 0 \\
        0 & 1 & 0 & \Delta t \\
        0 & 0 & 1 & 0 \\
        0 & 0 & 0 & 1
    \end{bmatrix},
\end{equation}
and $\mathbf{w}_{k-1} \sim \mathcal{N}(0, \mathbf{Q})$ is the process noise. The process noise covariance $\mathbf{Q}$ is modeled as a scaled identity matrix to reflect independent perturbations in all dimensions:
\begin{equation}
    \mathbf{Q} = \sigma^2_q \mathbf{I}_4,
\end{equation}
where $\sigma^2_q$ is the process noise variance hyperparameter.

\paragraph{Observation model.}

Each measurement at time step $k$ corresponds to a corrected range $d'_{A_i,T}$ between the tag $T$ and an anchor $A_i$ with known coordinates $\mathbf{p}_{A_i} = (x_{A_i}, y_{A_i})$. This relationship is governed by the nonlinear measurement function:
\begin{equation}
    z_k = h(\mathbf{x}_k) + v_k = \sqrt{(x_k - x_{A_i})^2 + (y_k - y_{A_i})^2} + v_k,
\end{equation}
where $v_k \sim \mathcal{N}(0, \mathbf{R}_k)$ is the measurement noise with variance $\mathbf{R}_k$. We note that only one anchor contributes a range measurement at each discrete time step, due to the TDMA scheduling structure (see \autoref{ranging_system} for the details).

The observation model is linearized around the current predicted state via its Jacobian $\mathbf{H}_k$:
\begin{equation}
\mathbf{H}_k = \frac{\partial h}{\partial \mathbf{x}} \big|_{\hat{\mathbf{x}}_k^-} = 
\begin{bmatrix}
    \dfrac{\hat{x}_k^- - x_{A_i}}{h(\hat{\mathbf{x}}_k^-)} &
    \dfrac{\hat{y}_k^- - y_{A_i}}{h(\hat{\mathbf{x}}_k^-)} &
    0 & 0
\end{bmatrix}.
\end{equation}

Prediction and update steps then follow the standard formulation described in \autoref{kalman_theory}.

% At each time step, the EKF performs the standard predict and update steps:
%% Moved to theoretical background

% \emph{Prediction:}
% \begin{align}
%     \hat{\mathbf{x}}_k^- &= \mathbf{F}_k \hat{\mathbf{x}}_{k-1} \\
%     \mathbf{P}_k^- &= \mathbf{F}_k \mathbf{P}_{k-1} \mathbf{F}_k^\top + \mathbf{Q}_k,
% \end{align}

% \emph{Update:}
% \begin{align}
%     \mathbf{K}_k &= \mathbf{P}_k^- \mathbf{H}_k^\top \left( \mathbf{H}_k \mathbf{P}_k^- \mathbf{H}_k^\top + R_k \right)^{-1} \\
%     \hat{\mathbf{x}}_k &= \hat{\mathbf{x}}_k^- + \mathbf{K}_k \left(z_k - h(\hat{\mathbf{x}}_k^-)\right) \\
%     \mathbf{P}_k &= \left(\mathbf{I} - \mathbf{K}_k \mathbf{H}_k\right) \mathbf{P}_k^-,
% \end{align}
% where $\mathbf{K}_k$ is the Kalman gain, $\hat{\mathbf{x}}_k$ is the posterior state estimate, and $\mathbf{P}_k$ is the corresponding covariance.
